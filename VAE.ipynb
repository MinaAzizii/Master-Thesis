{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNpC0vArG5Ury5TBUgAAtIx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinaAzizii/Master-Thesis/blob/Generative-Model/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        " !pip install torch==2.1.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        " !pip install torch-scatter -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
        " !pip install torch-sparse -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
        " !pip install torch-geometric\n"
      ],
      "metadata": {
        "id": "CG0GdiG25a6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install pandas openpyxl seaborn matplotlib tqdm scikit-learn\n",
        " !pip install numpy==1.24.4"
      ],
      "metadata": {
        "id": "N7RWHebX6rgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit-pypi"
      ],
      "metadata": {
        "id": "g0GpDByV7RNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PYTHON SCRIPT INITIALIZATION:\n",
        "# Imports required libraries for deep learning (PyTorch), data handling (pandas, NumPy), data preprocessing (scikit-learn), chemical structure parsing (RDKit), serialization (pickle), and reproducibility (random).\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from rdkit import Chem\n",
        "import pickle\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import NNConv, global_mean_pool\n",
        "from rdkit.Chem import Descriptors\n"
      ],
      "metadata": {
        "id": "K5hoi9y554P7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seeds for reproducibility; select GPU device for computations\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "whyjvFp256_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== LOAD DATA ====\n",
        "df = pd.read_excel(\"DB2.xlsx\")\n",
        "df = df.dropna(subset=[\"smiles\", \"solvent\", \"abs\"])\n",
        "# Only keep rows with valid SMILES and solvent\n",
        "is_valid_mol = df['smiles'].apply(lambda s: Chem.MolFromSmiles(s) is not None)\n",
        "is_valid_sol = df['solvent'].apply(lambda s: Chem.MolFromSmiles(s) is not None)\n",
        "df = df[is_valid_mol & is_valid_sol].reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "vl2KTIlc5-Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BUILD SMILES VOCABULARY:\n",
        "# - Constructs character-level vocabulary from SMILES strings.\n",
        "# - Adds special tokens: padding, start/end of sequence, unknown character.\n",
        "# - Provides mappings from characters to indices (stoi) and vice versa (itos).\n",
        "# - Defines functions for encoding SMILES to padded tensors and decoding tensors back to SMILES.\n",
        "# - Computes the maximum SMILES length (+2 for special tokens) for consistent tensor padding.\n",
        "def build_vocab(smiles_list):\n",
        "    tokens = set()\n",
        "    for s in smiles_list:\n",
        "        tokens.update(list(s))\n",
        "    tokens = sorted(tokens)\n",
        "    tokens = ['<PAD>', '<SOS>', '<EOS>', '<UNK>'] + tokens\n",
        "    stoi = {s:i for i,s in enumerate(tokens)}\n",
        "    itos = {i:s for i,s in enumerate(tokens)}\n",
        "    return tokens, stoi, itos\n",
        "\n",
        "def smiles_to_tensor(smiles, stoi, max_len):\n",
        "    arr = [stoi['<SOS>']] + [stoi.get(c, stoi['<UNK>']) for c in smiles] + [stoi['<EOS>']]\n",
        "    arr += [stoi['<PAD>']] * (max_len - len(arr))\n",
        "    return arr[:max_len]\n",
        "\n",
        "def tensor_to_smiles(tensor, itos):\n",
        "    chars = []\n",
        "    for idx in tensor:\n",
        "        c = itos[int(idx)]\n",
        "        if c == '<EOS>': break\n",
        "        if c not in ['<PAD>', '<SOS>']:\n",
        "            chars.append(c)\n",
        "    return ''.join(chars)\n",
        "\n",
        "smiles_list = df['smiles'].tolist()\n",
        "tokens, stoi, itos = build_vocab(smiles_list)\n",
        "lengths = [len(s) for s in smiles_list]\n",
        "max_len = max(lengths) + 2  # +2 for <SOS> and <EOS>\n",
        "print(f\"Max SMILES length in data: {max(lengths)}. Using max_len={max_len} for padding.\")"
      ],
      "metadata": {
        "id": "sFBtAd8t6CA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CONDITION: Lambda Absorption + Solvent One-Hot ====\n",
        "solv_enc = OneHotEncoder(sparse_output=False)\n",
        "solv_enc.fit(df[[\"solvent\"]])\n",
        "solv_oh = solv_enc.transform(df[[\"solvent\"]])\n",
        "scaler_abs = StandardScaler().fit(df[[\"abs\"]])  # For target conditioning\n",
        "\n",
        "cond_array = np.hstack([\n",
        "    scaler_abs.transform(df[[\"abs\"]]),  # 1D: scaled lambda absorption\n",
        "    solv_oh                             # one-hot: solvent\n",
        "])\n"
      ],
      "metadata": {
        "id": "f5PMPl2n6HJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MOLECULE DATASET AND DATALOADER:\n",
        "# - Defines custom PyTorch dataset class to encode SMILES strings as padded tensor sequences.\n",
        "# - Each dataset item consists of encoded SMILES tensor and associated conditional features.\n",
        "# - Creates DataLoader for efficient batch training.\n",
        "class MolDataset(Dataset):\n",
        "    def __init__(self, smiles_list, cond_list, stoi, max_len):\n",
        "        self.data = smiles_list\n",
        "        self.cond = cond_list\n",
        "        self.stoi = stoi\n",
        "        self.max_len = max_len\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        arr = smiles_to_tensor(self.data[idx], self.stoi, self.max_len)\n",
        "        return torch.tensor(arr, dtype=torch.long), torch.tensor(self.cond[idx], dtype=torch.float)\n",
        "\n",
        "dataset = MolDataset(smiles_list, cond_array, stoi, max_len)\n",
        "loader = DataLoader(dataset, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "r25qG3zC6MCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONDITIONAL SMILES VAE MODEL:\n",
        "# - Defines SMILES-based Variational Autoencoder (VAE) using GRU encoder-decoder.\n",
        "# - Encodes SMILES sequences to latent space and decodes back to sequences.\n",
        "# - Conditions latent vectors on external features (absorption & solvent).\n",
        "# - Uses reparameterization trick for differentiable sampling.\n",
        "# - Trains using CrossEntropy loss (reconstruction) plus KLD (latent regularization).\n",
        "# - Implements teacher forcing (80%) for efficient training.\n",
        "# - Trains for 40 epochs, saving trained model, vocabulary, and scalers.\n",
        "class SMILESVAE(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=128, hidden_dim=256, latent_dim=128, max_len=120, cond_dim=0):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.encoder = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.fc_mu = nn.Linear(hidden_dim*2, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_dim*2, latent_dim)\n",
        "        self.fc_z = nn.Linear(latent_dim+cond_dim, hidden_dim*2)\n",
        "        self.decoder = nn.GRU(emb_dim, hidden_dim*2, batch_first=True)\n",
        "        self.output = nn.Linear(hidden_dim*2, vocab_size)\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.embedding(x)\n",
        "        _, h = self.encoder(x)\n",
        "        h = h.transpose(0,1).reshape(x.size(0), -1)\n",
        "        mu = self.fc_mu(h)\n",
        "        logvar = self.fc_logvar(h)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        return mu + std * torch.randn_like(std)\n",
        "\n",
        "    def decode(self, z, cond=None, x=None, teacher_forcing=0.5):\n",
        "        if cond is not None:\n",
        "            z = torch.cat([z, cond], dim=1)\n",
        "        batch = z.size(0)\n",
        "        hidden = self.fc_z(z).unsqueeze(0)\n",
        "        input_token = torch.full((batch, 1), 1, device=z.device, dtype=torch.long)  # <SOS>\n",
        "        outputs = []\n",
        "        for t in range(self.max_len):\n",
        "            emb = self.embedding(input_token)\n",
        "            out, hidden = self.decoder(emb, hidden)\n",
        "            logits = self.output(out.squeeze(1))\n",
        "            outputs.append(logits)\n",
        "            if x is not None and torch.rand(1).item() < teacher_forcing:\n",
        "                input_token = x[:, t].unsqueeze(1)\n",
        "            else:\n",
        "                input_token = logits.argmax(dim=-1, keepdim=True)\n",
        "        return torch.stack(outputs, dim=1)\n",
        "\n",
        "    def forward(self, x, cond=None, teacher_forcing=0.5):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        out = self.decode(z, cond, x, teacher_forcing)\n",
        "        return out, mu, logvar\n",
        "\n",
        "vae_cond_dim = cond_array.shape[1]\n",
        "vae = SMILESVAE(len(tokens), max_len=max_len, cond_dim=vae_cond_dim)\n",
        "vae.to(device)\n",
        "opt = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=stoi['<PAD>'])\n",
        "\n",
        "print(\"Training Conditional SMILES VAE (lambda absorption + solvent)...\")\n",
        "for epoch in range(40):\n",
        "    vae.train()\n",
        "    total_loss = 0\n",
        "    for batch, cond in loader:\n",
        "        batch = batch.to(device)\n",
        "        cond = cond.to(device)\n",
        "        opt.zero_grad()\n",
        "        out, mu, logvar = vae(batch, cond, teacher_forcing=0.8)\n",
        "        loss_recon = loss_fn(out.view(-1, out.size(-1)), batch.view(-1))\n",
        "        kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / batch.size(0)\n",
        "        loss = loss_recon + 0.1 * kld\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss={total_loss/len(loader):.3f}\")\n",
        "\n",
        "torch.save(vae.state_dict(), \"smiles_vae_lambdaabs.pt\")\n",
        "with open(\"vocab_lambdaabs.pkl\", \"wb\") as f:\n",
        "    pickle.dump((tokens, stoi, itos, max_len), f)\n",
        "pickle.dump({\"solv_enc\": solv_enc, \"scaler_abs\": scaler_abs}, open(\"cond_scalers_lambdaabs.pkl\",\"wb\"))\n",
        "print(\"Saved VAE and vocab/scalers.\")"
      ],
      "metadata": {
        "id": "LXp_LIra6apf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SMILES GENERATION USING TRAINED VAE:\n",
        "# - Loads trained Conditional SMILES VAE, vocab, and scalers.\n",
        "# - Defines target absorption wavelength ranges and solvents.\n",
        "# - Generates specified number of molecules per solvent and wavelength.\n",
        "# - Saves generated molecules (SMILES) with associated solvent and target λ-absorption values to CSV.\n",
        "\n",
        "\n",
        "with open(\"vocab_lambdaabs.pkl\", \"rb\") as f:\n",
        "    tokens, stoi, itos, max_len = pickle.load(f)\n",
        "vae = SMILESVAE(len(tokens), max_len=max_len, cond_dim=vae_cond_dim)\n",
        "vae.load_state_dict(torch.load(\"smiles_vae_lambdaabs.pt\", map_location=\"cpu\"))\n",
        "vae = vae.to(\"cuda\")\n",
        "vae.eval()\n",
        "\n",
        "scalers = pickle.load(open(\"cond_scalers_lambdaabs.pkl\",\"rb\"))\n",
        "solv_enc = scalers[\"solv_enc\"]\n",
        "scaler_abs = scalers[\"scaler_abs\"]\n",
        "\n",
        "# --- User-defined generation targets ---\n",
        "solvents_list = df['solvent'].unique()  # Make sure 'df' contains your solvents\n",
        "\n",
        "ranges = [\n",
        "    (400, 410, \"400_410\"),\n",
        "    (490, 500, \"490_500\"),\n",
        "    (550, 560, \"550_560\"),\n",
        "    (640, 650, \"640_650\"),\n",
        "]\n",
        "\n",
        "num_per_condition = 100  # molecules per solvent per absorption\n",
        "batch_size = 20\n",
        "\n",
        "all_generated = []\n",
        "\n",
        "for (low, high, range_label) in ranges:\n",
        "    lambda_abs_range = np.linspace(low, high, 20)\n",
        "    print(f\"\\nGenerating for range: {low}-{high} nm\")\n",
        "    for i, solvent in enumerate(solvents_list):\n",
        "        print(f\"  Solvent {i+1}/{len(solvents_list)}: {solvent}\")\n",
        "        solv_oh = solv_enc.transform(pd.DataFrame([[solvent]], columns=[\"solvent\"]))[0]\n",
        "        for j, target_abs in enumerate(lambda_abs_range):\n",
        "            if j % 10 == 0:\n",
        "                print(f\"    Target abs {j+1}/{len(lambda_abs_range)}: {target_abs:.2f}\")\n",
        "            target_cond_np = np.hstack([\n",
        "                scaler_abs.transform(pd.DataFrame([[target_abs]], columns=[\"abs\"]))[0],\n",
        "                solv_oh\n",
        "            ])\n",
        "            target_cond = torch.tensor(target_cond_np, dtype=torch.float, device=vae.fc_mu.weight.device).unsqueeze(0)\n",
        "            batches = num_per_condition // batch_size\n",
        "            for _ in range(batches):\n",
        "                z = torch.randn(batch_size, vae.fc_mu.out_features, device=vae.fc_mu.weight.device)\n",
        "                cond_batch = target_cond.repeat(batch_size, 1)\n",
        "                with torch.no_grad():\n",
        "                    out = vae.decode(z, cond=cond_batch)\n",
        "                    preds = out.argmax(dim=-1).cpu().numpy()\n",
        "                    for pred in preds:\n",
        "                        smi = tensor_to_smiles(pred, itos)\n",
        "                        all_generated.append((solvent, float(target_abs), smi, range_label))\n",
        "            # Handle remainder if num_per_condition is not divisible by batch_size\n",
        "            remainder = num_per_condition % batch_size\n",
        "            if remainder:\n",
        "                z = torch.randn(remainder, vae.fc_mu.out_features, device=vae.fc_mu.weight.device)\n",
        "                cond_batch = target_cond.repeat(remainder, 1)\n",
        "                with torch.no_grad():\n",
        "                    out = vae.decode(z, cond=cond_batch)\n",
        "                    preds = out.argmax(dim=-1).cpu().numpy()\n",
        "                    for pred in preds:\n",
        "                        smi = tensor_to_smiles(pred, itos)\n",
        "                        all_generated.append((solvent, float(target_abs), smi, range_label))\n",
        "\n",
        "print(f\"\\nGeneration complete! Total molecules: {len(all_generated)}\")\n",
        "\n",
        "# Save as a DataFrame and CSV\n",
        "gen_df = pd.DataFrame(all_generated, columns=['solvent', 'target_abs', 'smiles', 'abs_range_label'])\n",
        "gen_df.to_csv(\"generated_molecules_multiple_ranges.csv\", index=False)\n",
        "print(\"Saved all generated molecules to generated_molecules_multiple_ranges.csv\")"
      ],
      "metadata": {
        "id": "xfXRbE8pPDGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VALIDATE AND FILTER GENERATED MOLECULES:\n",
        "def is_valid(smi):\n",
        "    return Chem.MolFromSmiles(smi) is not None\n",
        "\n",
        "def canonicalize(smi):\n",
        "    mol = Chem.MolFromSmiles(smi)\n",
        "    return Chem.MolToSmiles(mol) if mol else None\n",
        "\n",
        "# --- Load DB2 and prepare canonical set ---\n",
        "df_db2 = pd.read_excel(\"DB2.xlsx\")\n",
        "db2_smiles = df_db2[\"smiles\"].dropna()\n",
        "db2_cano_set = set(filter(None, (canonicalize(s) for s in db2_smiles)))\n",
        "\n",
        "# --- Load generated molecules ---\n",
        "df_gen = pd.read_csv(\"generated_molecules_multiple_ranges.csv\")\n",
        "\n",
        "# ✅ Step 1: Keep only valid SMILES\n",
        "df_gen[\"is_valid\"] = df_gen[\"smiles\"].apply(is_valid)\n",
        "df_gen_valid = df_gen[df_gen[\"is_valid\"]].copy()\n",
        "\n",
        "# ✅ Step 2: Canonicalize valid SMILES\n",
        "df_gen_valid[\"canonical\"] = df_gen_valid[\"smiles\"].apply(canonicalize)\n",
        "\n",
        "# ✅ Step 3: Remove duplicates within generated molecules\n",
        "df_gen_unique = df_gen_valid.drop_duplicates(subset=[\"canonical\"]).reset_index(drop=True)\n",
        "\n",
        "# ✅ Step 4: Remove SMILES that already exist in training set\n",
        "df_gen_final = df_gen_unique[~df_gen_unique[\"canonical\"].isin(db2_cano_set)].copy()\n",
        "\n",
        "# --- Clean and save ---\n",
        "df_gen_final = df_gen_final.drop(columns=[\"canonical\", \"is_valid\"])\n",
        "df_gen_final.to_csv(\"generated_molecules_multiple_ranges_valid_novel.csv\", index=False)\n",
        "\n",
        "print(f\"Saved {len(df_gen_final)} valid, novel, unique molecules to generated_molecules_multiple_ranges_valid_novel.csv\")\n"
      ],
      "metadata": {
        "id": "fR0-QAHv3KO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #PREDICT λ-ABSORPTION FOR GENERATED MOLECULES:\n",
        "mol_funcs = [\n",
        "    (\"Mol_MolWt\", Descriptors.MolWt),\n",
        "    (\"Mol_TPSA\", Descriptors.TPSA),\n",
        "    (\"Mol_NumRotatableBonds\", Descriptors.NumRotatableBonds),\n",
        "    (\"Mol_LogP\", Descriptors.MolLogP),\n",
        "    (\"Mol_Aromaticity\", Descriptors.NumAromaticRings),\n",
        "    (\"Mol_NumHDonors\", Descriptors.NumHDonors),\n",
        "    (\"Mol_NumHAcceptors\", Descriptors.NumHAcceptors),\n",
        "    (\"Mol_FractionCSP3\", Descriptors.FractionCSP3),\n",
        "    (\"Mol_HeteroatomCount\", Descriptors.HeavyAtomCount),\n",
        "]\n",
        "solvent_funcs = [\n",
        "    (\"Solv_MolWt\", Descriptors.MolWt),\n",
        "    (\"Solv_TPSA\", Descriptors.TPSA),\n",
        "    (\"Solv_MolLogP\", Descriptors.MolLogP),\n",
        "    (\"Solv_NumHDonors\", Descriptors.NumHDonors),\n",
        "]\n",
        "\n",
        "def compute_descriptors(smiles, func_list):\n",
        "    m = Chem.MolFromSmiles(smiles)\n",
        "    vals = []\n",
        "    for _, fn in func_list:\n",
        "        try:\n",
        "            v = fn(m)\n",
        "            vals.append(v if np.isfinite(v) else 0.0)\n",
        "        except:\n",
        "            vals.append(0.0)\n",
        "    return np.array(vals, dtype=float)\n",
        "\n",
        "def mol_to_graph(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    atoms = mol.GetAtoms()\n",
        "    heavy = [i for i, a in enumerate(atoms) if a.GetAtomicNum() > 1] or list(range(len(atoms)))\n",
        "    idx_map = {old: i for i, old in enumerate(heavy)}\n",
        "    x = torch.tensor([[atoms[i].GetAtomicNum(), atoms[i].GetFormalCharge(), atoms[i].GetNumExplicitHs()]\n",
        "                      for i in heavy], dtype=torch.float)\n",
        "    edges, attrs = [], []\n",
        "    for b in mol.GetBonds():\n",
        "        i, j = b.GetBeginAtomIdx(), b.GetEndAtomIdx()\n",
        "        if i in heavy and j in heavy:\n",
        "            ei, ej = idx_map[i], idx_map[j]\n",
        "            onehot = [int(b.GetBondType() == t) for t in\n",
        "                      (Chem.rdchem.BondType.SINGLE, Chem.rdchem.BondType.DOUBLE,\n",
        "                       Chem.rdchem.BondType.TRIPLE, Chem.rdchem.BondType.AROMATIC)]\n",
        "            edges += [[ei, ej], [ej, ei]]\n",
        "            attrs += [onehot, onehot]\n",
        "    if not edges:\n",
        "        edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
        "        edge_attr  = torch.zeros((0, 4), dtype=torch.float)\n",
        "    else:\n",
        "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "        edge_attr  = torch.tensor(attrs, dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "\n",
        "# --- Model definition (must match training!) ---\n",
        "class GCNEncoder(nn.Module):\n",
        "    def __init__(self, in_dim, hid, out_dim):\n",
        "        super().__init__()\n",
        "        self.e1 = nn.Sequential(nn.Linear(4, hid * in_dim), nn.ReLU(), nn.Linear(hid * in_dim, hid * in_dim))\n",
        "        self.e2 = nn.Sequential(nn.Linear(4, hid * hid), nn.ReLU(), nn.Linear(hid * hid, hid * hid))\n",
        "        self.e3 = nn.Sequential(nn.Linear(4, out_dim * hid), nn.ReLU(), nn.Linear(out_dim * hid, out_dim * hid))\n",
        "        self.c1 = NNConv(in_dim, hid, self.e1, aggr='mean')\n",
        "        self.c2 = NNConv(hid, hid, self.e2, aggr='mean')\n",
        "        self.c3 = NNConv(hid, out_dim, self.e3, aggr='mean')\n",
        "    def forward(self, x, ei, batch, ea):\n",
        "        x = self.c1(x, ei, ea).relu()\n",
        "        x = self.c2(x, ei, ea).relu()\n",
        "        x = self.c3(x, ei, ea).relu()\n",
        "        return global_mean_pool(x, batch)\n",
        "\n",
        "class SolvationPredictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.gcn_mol = GCNEncoder(3, 64, 64)\n",
        "        self.gcn_sol = GCNEncoder(3, 32, 64)\n",
        "        self.mlp_sol = nn.Sequential(nn.Linear(4, 64), nn.ReLU(), nn.Linear(64, 64))\n",
        "        self.mlp_mol = nn.Sequential(nn.Linear(9, 64), nn.ReLU(), nn.Linear(64, 64))\n",
        "        self.mlp_gcn = nn.Sequential(\n",
        "            nn.Linear(64 + 64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Linear(64 + 64 + 64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "    def forward(self, mg, sg, sdesc, mdesc):\n",
        "        me = self.gcn_mol(mg.x, mg.edge_index, mg.batch, mg.edge_attr)\n",
        "        se = self.gcn_sol(sg.x, sg.edge_index, sg.batch, sg.edge_attr)\n",
        "        sf = self.mlp_sol(sdesc)\n",
        "        mf = self.mlp_mol(mdesc)\n",
        "        gcn_cat = torch.cat([me, se], dim=-1)\n",
        "        gcn_out = self.mlp_gcn(gcn_cat)\n",
        "        cat = torch.cat([gcn_out, sf, mf], dim=-1)\n",
        "        return self.fuse(cat).squeeze(-1)\n",
        "\n",
        "# --- Load model and scalers ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SolvationPredictor().to(device)\n",
        "model.load_state_dict(torch.load('model_abs (1).pt', map_location=device))\n",
        "model.eval()\n",
        "\n",
        "with open(\"solv_scaler.pkl\", \"rb\") as f:\n",
        "    solv_scaler = pickle.load(f)\n",
        "with open(\"mol_scaler.pkl\", \"rb\") as f:\n",
        "    mol_scaler = pickle.load(f)\n",
        "with open(\"target_scaler.pkl\", \"rb\") as f:\n",
        "    target_scaler = pickle.load(f)\n",
        "\n",
        "# --- Load input dataset ---\n",
        "generated_df = pd.read_csv(\"generated_molecules_multiple_ranges_valid_novel.csv\")  # All columns preserved!\n",
        "\n",
        "# --- Predict lambda absorption for each row ---\n",
        "preds = []\n",
        "for idx, row in generated_df.iterrows():\n",
        "    smi = row['smiles']\n",
        "    solvent = row['solvent']\n",
        "    try:\n",
        "        # Prepare molecule graph and descriptors\n",
        "        mol_graph = mol_to_graph(smi)\n",
        "        mol_desc = compute_descriptors(smi, mol_funcs)\n",
        "        mol_desc_scaled = torch.tensor(mol_scaler.transform([mol_desc])[0], dtype=torch.float).unsqueeze(0).to(device)\n",
        "        # Prepare solvent graph and descriptors\n",
        "        solvent_graph = mol_to_graph(solvent)\n",
        "        solvent_desc = compute_descriptors(solvent, solvent_funcs)\n",
        "        solvent_desc_scaled = torch.tensor(solv_scaler.transform([solvent_desc])[0], dtype=torch.float).unsqueeze(0).to(device)\n",
        "        # Add batch info (single molecule = batch of 0s)\n",
        "        mol_graph = mol_graph.to(device)\n",
        "        solvent_graph = solvent_graph.to(device)\n",
        "        mol_graph.batch = torch.zeros(mol_graph.num_nodes, dtype=torch.long, device=device)\n",
        "        solvent_graph.batch = torch.zeros(solvent_graph.num_nodes, dtype=torch.long, device=device)\n",
        "        # Predict (scaled and real)\n",
        "        with torch.no_grad():\n",
        "            pred_scaled = model(mol_graph, solvent_graph, solvent_desc_scaled, mol_desc_scaled).cpu().numpy().item()\n",
        "            pred_real = target_scaler.inverse_transform([[pred_scaled]])[0, 0]\n",
        "            preds.append(pred_real)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed for SMILES: {smi}, Solvent: {solvent}, error: {e}\")\n",
        "        preds.append(np.nan)\n",
        "\n",
        "# --- Add predictions as new column and save ---\n",
        "generated_df[\"pred_lambda_abs\"] = preds\n",
        "generated_df.to_csv(\"generated_molecules_with_pred_lambda_abs.csv\", index=False)\n",
        "print(\"Saved predictions to generated_molecules_with_pred_lambda_abs.csv\")\n",
        "print(generated_df.head())"
      ],
      "metadata": {
        "id": "k0J5UYbsqXf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#Predict other optical properties\n",
        "mol_funcs = [\n",
        "    (\"Mol_MolWt\", Descriptors.MolWt),\n",
        "    (\"Mol_TPSA\", Descriptors.TPSA),\n",
        "    (\"Mol_NumRotatableBonds\", Descriptors.NumRotatableBonds),\n",
        "    (\"Mol_LogP\", Descriptors.MolLogP),\n",
        "    (\"Mol_Aromaticity\", Descriptors.NumAromaticRings),\n",
        "    (\"Mol_NumHDonors\", Descriptors.NumHDonors),\n",
        "    (\"Mol_NumHAcceptors\", Descriptors.NumHAcceptors),\n",
        "    (\"Mol_FractionCSP3\", Descriptors.FractionCSP3),\n",
        "    (\"Mol_HeteroatomCount\", Descriptors.HeavyAtomCount),\n",
        "]\n",
        "solvent_funcs = [\n",
        "    (\"Solv_MolWt\", Descriptors.MolWt),\n",
        "    (\"Solv_TPSA\", Descriptors.TPSA),\n",
        "    (\"Solv_MolLogP\", Descriptors.MolLogP),\n",
        "    (\"Solv_NumHDonors\", Descriptors.NumHDonors),\n",
        "]\n",
        "\n",
        "def compute_descriptors(smiles, func_list):\n",
        "    m = Chem.MolFromSmiles(smiles)\n",
        "    vals = []\n",
        "    for _, fn in func_list:\n",
        "        try:\n",
        "            v = fn(m)\n",
        "            vals.append(v if np.isfinite(v) else 0.0)\n",
        "        except:\n",
        "            vals.append(0.0)\n",
        "    return np.array(vals, dtype=float)\n",
        "\n",
        "def mol_to_graph(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    atoms = mol.GetAtoms()\n",
        "    heavy = [i for i, a in enumerate(atoms) if a.GetAtomicNum() > 1] or list(range(len(atoms)))\n",
        "    idx_map = {old: i for i, old in enumerate(heavy)}\n",
        "    x = torch.tensor([[atoms[i].GetAtomicNum(), atoms[i].GetFormalCharge(), atoms[i].GetNumExplicitHs()]\n",
        "                      for i in heavy], dtype=torch.float)\n",
        "    edges, attrs = [], []\n",
        "    for b in mol.GetBonds():\n",
        "        i, j = b.GetBeginAtomIdx(), b.GetEndAtomIdx()\n",
        "        if i in heavy and j in heavy:\n",
        "            ei, ej = idx_map[i], idx_map[j]\n",
        "            onehot = [int(b.GetBondType() == t) for t in\n",
        "                      (Chem.rdchem.BondType.SINGLE, Chem.rdchem.BondType.DOUBLE,\n",
        "                       Chem.rdchem.BondType.TRIPLE, Chem.rdchem.BondType.AROMATIC)]\n",
        "            edges += [[ei, ej], [ej, ei]]\n",
        "            attrs += [onehot, onehot]\n",
        "    if not edges:\n",
        "        edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
        "        edge_attr  = torch.zeros((0, 4), dtype=torch.float)\n",
        "    else:\n",
        "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "        edge_attr  = torch.tensor(attrs, dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "\n",
        "# --- 2. MODEL DEFINITION (as used in training) ---\n",
        "class GCNEncoder(nn.Module):\n",
        "    def __init__(self, in_dim, hid, out_dim):\n",
        "        super().__init__()\n",
        "        self.e1 = nn.Sequential(nn.Linear(4, hid * in_dim), nn.ReLU(), nn.Linear(hid * in_dim, hid * in_dim))\n",
        "        self.e2 = nn.Sequential(nn.Linear(4, hid * hid), nn.ReLU(), nn.Linear(hid * hid, hid * hid))\n",
        "        self.e3 = nn.Sequential(nn.Linear(4, out_dim * hid), nn.ReLU(), nn.Linear(out_dim * hid, out_dim * hid))\n",
        "        self.c1 = NNConv(in_dim, hid, self.e1, aggr='mean')\n",
        "        self.c2 = NNConv(hid, hid, self.e2, aggr='mean')\n",
        "        self.c3 = NNConv(hid, out_dim, self.e3, aggr='mean')\n",
        "    def forward(self, x, ei, batch, ea):\n",
        "        x = self.c1(x, ei, ea).relu()\n",
        "        x = self.c2(x, ei, ea).relu()\n",
        "        x = self.c3(x, ei, ea).relu()\n",
        "        return global_mean_pool(x, batch)\n",
        "\n",
        "class SolvationPredictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.gcn_mol = GCNEncoder(3, 64, 64)\n",
        "        self.gcn_sol = GCNEncoder(3, 32, 64)\n",
        "        self.mlp_sol = nn.Sequential(nn.Linear(4, 64), nn.ReLU(), nn.Linear(64, 64))\n",
        "        self.mlp_mol = nn.Sequential(nn.Linear(9, 64), nn.ReLU(), nn.Linear(64, 64))\n",
        "        self.mlp_gcn = nn.Sequential(\n",
        "            nn.Linear(64 + 64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Linear(64 + 64 + 64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "    def forward(self, mg, sg, sdesc, mdesc):\n",
        "        me = self.gcn_mol(mg.x, mg.edge_index, mg.batch, mg.edge_attr)\n",
        "        se = self.gcn_sol(sg.x, sg.edge_index, sg.batch, sg.edge_attr)\n",
        "        sf = self.mlp_sol(sdesc)\n",
        "        mf = self.mlp_mol(mdesc)\n",
        "        gcn_cat = torch.cat([me, se], dim=-1)\n",
        "        gcn_out = self.mlp_gcn(gcn_cat)\n",
        "        cat = torch.cat([gcn_out, sf, mf], dim=-1)\n",
        "        return self.fuse(cat).squeeze(-1)\n",
        "\n",
        "# --- 3. LOAD INPUT DATASET ---\n",
        "input_file = \"generated_molecules_with_pred_lambda_abs.csv\"\n",
        "df = pd.read_csv(input_file)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --- 4. LOAD ALL MODELS AND SCALERS ---\n",
        "# Emission\n",
        "model_em = SolvationPredictor().to(device)\n",
        "model_em.load_state_dict(torch.load('model_emi.pt', map_location=device))\n",
        "model_em.eval()\n",
        "with open(\"mol_scaler_emission.pkl\", \"rb\") as f: mol_scaler_em = pickle.load(f)\n",
        "with open(\"solv_scaler_emission.pkl\", \"rb\") as f: solv_scaler_em = pickle.load(f)\n",
        "with open(\"target_scaler_emission.pkl\", \"rb\") as f: target_scaler_em = pickle.load(f)\n",
        "\n",
        "# Epsilon\n",
        "model_eps = SolvationPredictor().to(device)\n",
        "model_eps.load_state_dict(torch.load('model_epsilon.pt', map_location=device))\n",
        "model_eps.eval()\n",
        "with open(\"mol_scaler_Epsilon.pkl\", \"rb\") as f: mol_scaler_eps = pickle.load(f)\n",
        "with open(\"solv_scaler_Epsilon.pkl\", \"rb\") as f: solv_scaler_eps = pickle.load(f)\n",
        "\n",
        "\n",
        "# QY\n",
        "model_qy = SolvationPredictor().to(device)\n",
        "model_qy.load_state_dict(torch.load('model_QY.pt', map_location=device))\n",
        "model_qy.eval()\n",
        "with open(\"mol_scaler_QY.pkl\", \"rb\") as f: mol_scaler_qy = pickle.load(f)\n",
        "with open(\"solv_scaler_QY.pkl\", \"rb\") as f: solv_scaler_qy = pickle.load(f)\n",
        "# QY target is NOT scaled\n",
        "\n",
        "# --- 5. PREDICTION FUNCTIONS ---\n",
        "def predict_emission(row):\n",
        "    smi, solv = row['smiles'], row['solvent']\n",
        "    try:\n",
        "        mol_graph = mol_to_graph(smi)\n",
        "        mol_desc = compute_descriptors(smi, mol_funcs)\n",
        "        mol_desc_scaled = torch.tensor(mol_scaler_em.transform([mol_desc])[0], dtype=torch.float).unsqueeze(0).to(device)\n",
        "        solv_graph = mol_to_graph(solv)\n",
        "        solv_desc = compute_descriptors(solv, solvent_funcs)\n",
        "        solv_desc_scaled = torch.tensor(solv_scaler_em.transform([solv_desc])[0], dtype=torch.float).unsqueeze(0).to(device)\n",
        "        mol_graph = mol_graph.to(device)\n",
        "        solv_graph = solv_graph.to(device)\n",
        "        mol_graph.batch = torch.zeros(mol_graph.num_nodes, dtype=torch.long, device=device)\n",
        "        solv_graph.batch = torch.zeros(solv_graph.num_nodes, dtype=torch.long, device=device)\n",
        "        with torch.no_grad():\n",
        "            pred_scaled = model_em(mol_graph, solv_graph, solv_desc_scaled, mol_desc_scaled).cpu().numpy().item()\n",
        "            pred_real = target_scaler_em.inverse_transform([[pred_scaled]])[0, 0]\n",
        "        return pred_real\n",
        "    except Exception as e:\n",
        "        print(f\"Emission prediction failed for {smi} in {solv}: {e}\")\n",
        "        return None\n",
        "\n",
        "def predict_epsilon(row):\n",
        "    smi, solv = row['smiles'], row['solvent']\n",
        "    try:\n",
        "        mol_graph = mol_to_graph(smi)\n",
        "        mol_desc = compute_descriptors(smi, mol_funcs)\n",
        "        mol_desc_scaled = torch.tensor(mol_scaler_eps.transform([mol_desc])[0], dtype=torch.float).unsqueeze(0).to(device)\n",
        "        solv_graph = mol_to_graph(solv)\n",
        "        solv_desc = compute_descriptors(solv, solvent_funcs)\n",
        "        solv_desc_scaled = torch.tensor(solv_scaler_eps.transform([solv_desc])[0], dtype=torch.float).unsqueeze(0).to(device)\n",
        "        mol_graph = mol_graph.to(device)\n",
        "        solv_graph = solv_graph.to(device)\n",
        "        mol_graph.batch = torch.zeros(mol_graph.num_nodes, dtype=torch.long, device=device)\n",
        "        solv_graph.batch = torch.zeros(solv_graph.num_nodes, dtype=torch.long, device=device)\n",
        "        with torch.no_grad():\n",
        "            pred_logeps = model_eps(mol_graph, solv_graph, solv_desc_scaled, mol_desc_scaled).cpu().numpy().item()\n",
        "        return pred_logeps\n",
        "    except Exception as e:\n",
        "        print(f\"Epsilon prediction failed for {smi} in {solv}: {e}\")\n",
        "        return None\n",
        "\n",
        "def predict_QY(row):\n",
        "    smi, solv = row['smiles'], row['solvent']\n",
        "    try:\n",
        "        mol_graph = mol_to_graph(smi)\n",
        "        mol_desc = compute_descriptors(smi, mol_funcs)\n",
        "        mol_desc_scaled = torch.tensor(mol_scaler_qy.transform([mol_desc])[0], dtype=torch.float).unsqueeze(0).to(device)\n",
        "        solv_graph = mol_to_graph(solv)\n",
        "        solv_desc = compute_descriptors(solv, solvent_funcs)\n",
        "        solv_desc_scaled = torch.tensor(solv_scaler_qy.transform([solv_desc])[0], dtype=torch.float).unsqueeze(0).to(device)\n",
        "        mol_graph = mol_graph.to(device)\n",
        "        solv_graph = solv_graph.to(device)\n",
        "        mol_graph.batch = torch.zeros(mol_graph.num_nodes, dtype=torch.long, device=device)\n",
        "        solv_graph.batch = torch.zeros(solv_graph.num_nodes, dtype=torch.long, device=device)\n",
        "        with torch.no_grad():\n",
        "            pred_real = model_qy(mol_graph, solv_graph, solv_desc_scaled, mol_desc_scaled).cpu().numpy().item()\n",
        "        return pred_real\n",
        "    except Exception as e:\n",
        "        print(f\"QY prediction failed for {smi} in {solv}: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- 6. APPLY PREDICTIONS ---\n",
        "print(\"Predicting emission...\")\n",
        "df['pred_lambda_em'] = df.apply(predict_emission, axis=1)\n",
        "print(\"Predicting epsilon...\")\n",
        "df['pred_epsilon'] = df.apply(predict_epsilon, axis=1)\n",
        "print(\"Predicting QY...\")\n",
        "df['pred_QY'] = df.apply(predict_QY, axis=1)\n",
        "df['brightness'] = df['pred_epsilon'] * df['pred_QY']\n",
        "\n",
        "# --- 7. SAVE FINAL PREDICTIONS ---\n",
        "df.to_csv(\"generated_molecules_with_all_predictions.csv\", index=False)\n",
        "print(\"Saved all predictions to generated_molecules_with_all_predictions.csv\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "a1cLhdWmfULq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}